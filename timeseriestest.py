# -*- coding: utf-8 -*-
"""TimeseriesTest.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19zJlaQu55munpB4GJWCvO-3dcNkWNGAV
"""

# Commented out IPython magic to ensure Python compatibility.
#Import libaries

import pandas as pd
import holoviews as hv
from prophet import Prophet
import hvplot.pandas
import datetime as dt
import matplotlib.pyplot as plt
# %matplotlib inline
import numpy as np

# Upload the "google_hourly_search_trends.csv" file into Colab, then store in a Pandas DataFrame
# Set the "Date" column as the Datetime Index.
from google.colab import files
uploaded = files.upload()

df_mercado_trends = pd.read_csv(
    "google_hourly_search_trends.csv",
    index_col='Date', 
    parse_dates=True, 
    infer_datetime_format=True
).dropna()

# Review the DataFrame
df_mercado_trends.head()

#Read dataframe

df_mercado_trends.info()

#display last 5 of data

df_mercado_trends.tail()

# Holoviews extension to render hvPlots in Colab
hv.extension('bokeh')

# Slice the DataFrame to just the month of May 2020
df_may_2020 = df_mercado_trends.loc["2020-05-01" : "2020-05-31"]

# Use hvPlot to visualize the data for May 2020
df_may_2020.hvplot()

# Calculate the sum of the total search traffic for May 2020

traffic_may_2020 = df_may_2020.sum()

traffic_may_2020

# Calcluate the monhtly median search traffic across all months 
# Group the DataFrame by index year and then index month, chain the sum and then the median functions

df_mercado_trends.groupby(by=[df_mercado_trends.index.year, df_mercado_trends.index.month]).sum().median()

# Compare the seach traffic for the month of May 2020 to the overall monthly median value

comparison_for_traffic = traffic_may_2020 / 35171.5
comparison_for_traffic

#Traffic increased on google search after MercadoLibre  dropped it's financial results

# Use hvPlot to visualize the hour of the day and day of week search traffic as a heatmap.

hv.extension('bokeh')
df_mercado_trends.groupby(by=[df_mercado_trends.index.hour]).sum()
df_mercado_trends.hvplot.heatmap(
    x='index.hour',
     y='index.dayofweek',
      C='Search Trends',
       cmap='reds'
).aggregate(function=np.mean)

#: Does the search traffic tend to increase during the winter holiday period (weeks 40 through 52)?
# you see a significante incrase in traffice during the winter holidays and not so much during the summer
#holidays as you can tell by the lighter colors from the graph espcially weeks 5 throuh 25.

# Upload the "mercado_stock_price.csv" file into Colab, then store in a Pandas DataFrame
# Set the "date" column as the Datetime Index.
from google.colab import files
uploaded = files.upload()

df_mercado_stock = pd.read_csv(
    "mercado_stock_price.csv",
    index_col='date', 
    parse_dates=True, 
    infer_datetime_format=True
).dropna()

df_mercado_stock.head()

# Holoviews extension to render hvPlots in Colab
hv.extension('bokeh')

df_mercado_stock.hvplot()

#Add dataframe together for close prices and search trends to see comp

mercado_stock_trends_df = pd.concat([df_mercado_stock, df_mercado_trends], axis=1).dropna()

mercado_stock_trends_df.head()

#See last 5 of data

mercado_stock_trends_df.tail()

#see first half of 2020 trend of close price and search 

first_half_2020 = mercado_stock_trends_df.loc["2020-01" : "2020-06"]
first_half_2020.head()

#See how last 5 of data looked like compared to first 5 

first_half_2020.tail()

#Plot comparison between close price and search trend see correlation

hv.extension('bokeh')
first_half_2020.hvplot(shared_axes=False, subplots=True).cols(1)

# Do both time series indicate a common trend thatâ€™s consistent with this narrative?

#Based on this data I would say in March when the data dropped from are company you can
#see the correlation between the price of the stock and the decrease in search trends 
#other than that there does not seem to be much of a correlation in my opinion.

#see lagged trend shifting down one for search trends 

mercado_stock_trends_df['Lagged Search Trends'] = mercado_stock_trends_df['Search Trends'].shift(1)

#Compare stock volatility 

mercado_stock_trends_df['Stock Volatility'] = mercado_stock_trends_df['close'].pct_change().rolling(window=4).std()

#Show stock volatility graph with hvplot 

hv.extension('bokeh')

mercado_stock_trends_df['Stock Volatility'].hvplot()

#show stock return by the hour 

mercado_stock_trends_df['Hourly Stock Return'] = mercado_stock_trends_df['close'].shift(1)

#disply table of data to show trends 

mercado_stock_trends_df.head()

#Show last 5 of data frame see how it was a significant change after results from company where released

mercado_stock_trends_df.tail()

#Create new dataframe showing lagged stock and hourly return correlation if any 

mercado_stock_trends_df[["Lagged Search Trends", "Stock Volatility", "Hourly Stock Return"]].corr()

#: Does a predictable relationship exist between the lagged search traffic and the stock volatility or between the lagged search traffic and the stock price returns?

# there seems to be a positive correlation between lagged search trends and hourly stock return

#Read in google hourly search trends 

mercado_prophet_df = pd.read_csv(
    "google_hourly_search_trends.csv", 
    parse_dates=True, 
    infer_datetime_format=True
).dropna()

# Review the DataFrame
mercado_prophet_df.head().dropna()

#Rename columns to fit facebook prophet 

mercado_prophet_df = mercado_prophet_df.rename(columns={"Date":"ds", "Search Trends":"y"})

#Display datahead 

mercado_prophet_df.head()

#Show data tail 

mercado_prophet_df.tail()

#Create model 

model_mercado = Prophet()

#Fit model 

model_mercado.fit(mercado_prophet_df)

#run prediction module over 2000 hours 

future_mercado_trends = model_mercado.make_future_dataframe(periods=2000, freq="H")
future_mercado_trends.head()

#show tail end of data

future_mercado_trends.tail()

#Run perdiction model show data 

forecast_mercado_trends = model_mercado.predict(future_mercado_trends)
forecast_mercado_trends.head()

#Display forecast perdiction graph 

model_mercado.plot(forecast_mercado_trends)

#How's the near-term forecast for the popularity of MercadoLibre?

#The term-forecast of MercadoLibre seems to be decreasing in popularity

#Show prediction graph as yhat is the target and yhat_upper would be the dream for probability of success.

forecast_mercado_trends[['yhat', 'yhat_lower', 'yhat_upper']].iloc[-52:,:].plot()

#Show probability over a year of the company using hourly prices as metrics 

hv.extension('bokeh')
forecast_mercado_trends[['yhat', 'yhat_lower', 'yhat_upper']].iloc[-52:,:].hvplot()

#Reset index show prediction over hours, years and weeks to see how mercado responded in different timeframes. 

forecast_mercado_trends = forecast_mercado_trends.reset_index()
fig_mercado = model_mercado.plot_components(forecast_mercado_trends)

#What time of day exhibits the greatest popularity?

#Early in the morning before 3pm and late at night afer midnight show the greatest populatrity 

#Which day of week gets the most search traffic?

#Tuesday get's the most search traffic during the week

# What's the lowest point for search traffic in the calendar year?

# Novemeber seems to be the lowest point of the year for search traffic.

#Start on mercado revenue to help project sales 

from google.colab import files
uploaded = files.upload()

df_mercado_sales = pd.read_csv(
    "mercado_daily_revenue.csv",
    index_col='date', 
    parse_dates=True, 
    infer_datetime_format=True
).dropna()

# Review the DataFrame
df_mercado_sales.head()

#display data in graph.

hv.extension('bokeh')

df_mercado_sales.hvplot()

